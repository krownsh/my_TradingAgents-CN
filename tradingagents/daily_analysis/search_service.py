# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ± - æœå°‹æœå‹™æ¨¡çµ„
===================================

è·è²¬ï¼š
1. æä¾›çµ±ä¸€çš„æ–°èæœå°‹ä»‹é¢
2. æ”¯æ´ Tavily å’Œ SerpAPI å…©ç¨®æœå°‹å¼•æ“
3. å¤š Key è² è¼‰å‡è¡¡å’Œæ•…éšœè½‰ç§»
4. æœå°‹çµæœå¿«å–å’Œæ ¼å¼åŒ–
"""

import logging
import random
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional
from itertools import cycle
import requests
from newspaper import Article, Config

logger = logging.getLogger(__name__)


def fetch_url_content(url: str, timeout: int = 5) -> str:
    """
    ç²å– URL ç¶²é æ­£æ–‡å…§å®¹ (ä½¿ç”¨ newspaper3k)
    """
    try:
        # è¨­å®š newspaper3k
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        config.request_timeout = timeout
        config.fetch_images = False  # ä¸ä¸‹è¼‰åœ–ç‰‡
        config.memoize_articles = False # ä¸å¿«å–

        article = Article(url, config=config, language='zh') # é è¨­ä¸­æ–‡ï¼Œä½†ä¹Ÿæ”¯æ´å…¶ä»–
        article.download()
        article.parse()

        # ç²å–æ­£æ–‡
        text = article.text.strip()

        # ç°¡å–®çš„å¾Œè™•ç†ï¼Œå»é™¤ç©ºè¡Œ
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        return text[:1500]  # é™åˆ¶è¿”å›é•·åº¦ï¼ˆæ¯” bs4 ç¨å¾®å¤šä¸€é»ï¼Œå› ç‚º newspaper è§£ææ›´ä¹¾æ·¨ï¼‰
    except Exception as e:
        logger.debug(f"Fetch content failed for {url}: {e}")

    return ""


@dataclass
class SearchResult:
    """æœå°‹çµæœè³‡æ–™é¡åˆ¥"""
    title: str
    snippet: str  # æ‘˜è¦
    url: str
    source: str  # ä¾†æºç¶²ç«™
    published_date: Optional[str] = None
    
    def to_text(self) -> str:
        """è½‰æ›ç‚ºæ–‡å­—æ ¼å¼"""
        date_str = f" ({self.published_date})" if self.published_date else ""
        return f"ã€{self.source}ã€‘{self.title}{date_str}\n{self.snippet}"


@dataclass 
class SearchResponse:
    """æœå°‹å›æ‡‰"""
    query: str
    results: List[SearchResult]
    provider: str  # ä½¿ç”¨çš„æœå°‹å¼•æ“
    success: bool = True
    error_message: Optional[str] = None
    search_time: float = 0.0  # æœå°‹è€—æ™‚ï¼ˆç§’ï¼‰
    
    def to_context(self, max_results: int = 5) -> str:
        """å°‡æœå°‹çµæœè½‰æ›ç‚ºå¯ç”¨æ–¼ AI åˆ†æçš„ä¸Šä¸‹æ–‡"""
        if not self.success or not self.results:
            return f"æœå°‹ '{self.query}' æœªæ‰¾åˆ°ç›¸é—œçµæœã€‚"
        
        lines = [f"ã€{self.query} æœå°‹çµæœã€‘ï¼ˆä¾†æºï¼š{self.provider}ï¼‰"]
        for i, result in enumerate(self.results[:max_results], 1):
            lines.append(f"\n{i}. {result.to_text()}")
        
        return "\n".join(lines)


class BaseSearchProvider(ABC):
    """æœå°‹å¼•æ“åŸºé¡"""
    
    def __init__(self, api_keys: List[str], name: str):
        """
        åˆå§‹åŒ–æœå°‹å¼•æ“
        
        Args:
            api_keys: API Key åˆ—è¡¨ï¼ˆæ”¯æ´å¤šå€‹ key è² è¼‰å‡è¡¡ï¼‰
            name: æœå°‹å¼•æ“åç¨±
        """
        self._api_keys = api_keys
        self._name = name
        self._key_cycle = cycle(api_keys) if api_keys else None
        self._key_usage: Dict[str, int] = {key: 0 for key in api_keys}
        self._key_errors: Dict[str, int] = {key: 0 for key in api_keys}
    
    @property
    def name(self) -> str:
        return self._name
    
    @property
    def is_available(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ API Key"""
        return bool(self._api_keys)
    
    def _get_next_key(self) -> Optional[str]:
        """
        ç²å–ä¸‹ä¸€å€‹å¯ç”¨çš„ API Keyï¼ˆè² è¼‰å‡è¡¡ï¼‰
        
        ç­–ç•¥ï¼šè¼ªè©¢ + è·³ééŒ¯èª¤éå¤šçš„ key
        """
        if not self._key_cycle:
            return None
        
        # æœ€å¤šå˜—è©¦æ‰€æœ‰ key
        for _ in range(len(self._api_keys)):
            key = next(self._key_cycle)
            # è·³ééŒ¯èª¤æ¬¡æ•¸éå¤šçš„ keyï¼ˆè¶…é 3 æ¬¡ï¼‰
            if self._key_errors.get(key, 0) < 3:
                return key
        
        # æ‰€æœ‰ key éƒ½æœ‰å•é¡Œï¼Œé‡ç½®éŒ¯èª¤è¨ˆæ•¸ä¸¦è¿”å›ç¬¬ä¸€å€‹
        logger.warning(f"[{self._name}] æ‰€æœ‰ API Key éƒ½æœ‰éŒ¯èª¤è¨˜éŒ„ï¼Œé‡ç½®éŒ¯èª¤è¨ˆæ•¸")
        self._key_errors = {key: 0 for key in self._api_keys}
        return self._api_keys[0] if self._api_keys else None
    
    def _record_success(self, key: str) -> None:
        """è¨˜éŒ„æˆåŠŸä½¿ç”¨"""
        self._key_usage[key] = self._key_usage.get(key, 0) + 1
        # æˆåŠŸå¾Œæ¸›å°‘éŒ¯èª¤è¨ˆæ•¸
        if key in self._key_errors and self._key_errors[key] > 0:
            self._key_errors[key] -= 1
    
    def _record_error(self, key: str) -> None:
        """è¨˜éŒ„éŒ¯èª¤"""
        self._key_errors[key] = self._key_errors.get(key, 0) + 1
        logger.warning(f"[{self._name}] API Key {key[:8]}... éŒ¯èª¤è¨ˆæ•¸: {self._key_errors[key]}")
    
    @abstractmethod
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        """åŸ·è¡Œæœå°‹ï¼ˆå­é¡å¯¦ç¾ï¼‰"""
        pass
    
    def search(self, query: str, max_results: int = 5, days: int = 7) -> SearchResponse:
        """
        åŸ·è¡Œæœå°‹
        
        Args:
            query: æœå°‹é—œéµè©
            max_results: æœ€å¤§è¿”å›çµæœæ•¸
            days: æœå°‹æœ€è¿‘å¹¾å¤©çš„æ™‚é–“ç¯„åœï¼ˆé è¨­7å¤©ï¼‰
            
        Returns:
            SearchResponse ç‰©ä»¶
        """
        api_key = self._get_next_key()
        if not api_key:
            return SearchResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=f"{self._name} æœªé…ç½® API Key"
            )
        
        start_time = time.time()
        try:
            response = self._do_search(query, api_key, max_results, days=days)
            response.search_time = time.time() - start_time
            
            if response.success:
                self._record_success(api_key)
                logger.info(f"[{self._name}] æœå°‹ '{query}' æˆåŠŸï¼Œè¿”å› {len(response.results)} æ¢çµæœï¼Œè€—æ™‚ {response.search_time:.2f}s")
            else:
                self._record_error(api_key)
            
            return response
            
        except Exception as e:
            self._record_error(api_key)
            elapsed = time.time() - start_time
            logger.error(f"[{self._name}] æœå°‹ '{query}' å¤±æ•—: {e}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=str(e),
                search_time=elapsed
            )


class TavilySearchProvider(BaseSearchProvider):
    """
    Tavily æœå°‹å¼•æ“
    
    ç‰¹é»ï¼š
    - å°ˆç‚º AI/LLM å„ªåŒ–çš„æœå°‹ API
    - å…è²»ç‰ˆæ¯æœˆ 1000 æ¬¡è«‹æ±‚
    - è¿”å›çµæ§‹åŒ–çš„æœå°‹çµæœ
    
    æ–‡ä»¶ï¼šhttps://docs.tavily.com/
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Tavily")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        """åŸ·è¡Œ Tavily æœå°‹"""
        try:
            from tavily import TavilyClient
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="tavily-python æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install tavily-python"
            )
        
        try:
            client = TavilyClient(api_key=api_key)
            
            # åŸ·è¡Œæœå°‹ï¼ˆå„ªåŒ–ï¼šä½¿ç”¨ advanced æ·±åº¦ã€é™åˆ¶æœ€è¿‘å¹¾å¤©ï¼‰
            response = client.search(
                query=query,
                search_depth="advanced",  # advanced ç²å–æ›´å¤šçµæœ
                max_results=max_results,
                include_answer=False,
                include_raw_content=False,
                days=days,  # æœå°‹æœ€è¿‘å¤©æ•¸çš„å…§å®¹
            )
            
            # è¨˜éŒ„åŸå§‹å›æ‡‰åˆ°æ—¥èªŒ
            logger.info(f"[Tavily] æœå°‹å®Œæˆï¼Œquery='{query}', è¿”å› {len(response.get('results', []))} æ¢çµæœ")
            logger.debug(f"[Tavily] åŸå§‹å›æ‡‰: {response}")
            
            # è§£æçµæœ
            results = []
            for item in response.get('results', []):
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('content', '')[:500],  # æˆªå–å‰ 500 å­—
                    url=item.get('url', ''),
                    source=self._extract_domain(item.get('url', '')),
                    published_date=item.get('published_date'),
                ))
            
            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except Exception as e:
            error_msg = str(e)
            # æª¢æŸ¥æ˜¯å¦ç‚ºé…é¡å•é¡Œ
            if 'rate limit' in error_msg.lower() or 'quota' in error_msg.lower():
                error_msg = f"API é…é¡å·²ç”¨ç›¡: {error_msg}"
            
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """å¾ URL æå–åŸŸåä½œç‚ºä¾†æº"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc.replace('www.', '')
            return domain or 'æœªçŸ¥ä¾†æº'
        except:
            return 'æœªçŸ¥ä¾†æº'


class SerpAPISearchProvider(BaseSearchProvider):
    """
    SerpAPI æœå°‹å¼•æ“
    
    ç‰¹é»ï¼š
    - æ”¯æ´ Googleã€Bingã€ç™¾åº¦ç­‰å¤šç¨®æœå°‹å¼•æ“
    - å…è²»ç‰ˆæ¯æœˆ 100 æ¬¡è«‹æ±‚
    - è¿”å›çœŸå¯¦çš„æœå°‹çµæœ
    
    æ–‡ä»¶ï¼šhttps://serpapi.com/baidu-search-api?utm_source=github_daily_stock_analysis
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "SerpAPI")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        """åŸ·è¡Œ SerpAPI æœå°‹"""
        try:
            from serpapi import GoogleSearch
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="google-search-results æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install google-search-results"
            )
        
        try:
            # ç¢ºå®šæ™‚é–“ç¯„åœåƒæ•¸ tbs
            tbs = "qdr:w"  # é è¨­ä¸€é€±
            if days <= 1:
                tbs = "qdr:d"  # éå» 24 å°æ™‚
            elif days <= 7:
                tbs = "qdr:w"  # éå»ä¸€é€±
            elif days <= 30:
                tbs = "qdr:m"  # éå»ä¸€æœˆ
            else:
                tbs = "qdr:y"  # éå»ä¸€å¹´

            # ä½¿ç”¨ Google æœå°‹ (ç²å– Knowledge Graph, Answer Box ç­‰)
            params = {
                "engine": "google",
                "q": query,
                "api_key": api_key,
                "google_domain": "google.com.hk", # ä½¿ç”¨é¦™æ¸¯ Googleï¼Œä¸­æ–‡æ”¯æ´è¼ƒå¥½
                "hl": "zh-tw",  # ç¹é«”ä¸­æ–‡ä»‹é¢
                "gl": "tw",     # å°ç£åœ°å€åå¥½
                "tbs": tbs,     # æ™‚é–“ç¯„åœé™åˆ¶
                "num": max_results # è«‹æ±‚çš„çµæœæ•¸é‡ï¼Œæ³¨æ„ï¼šGoogle API æœ‰æ™‚ä¸åš´æ ¼éµå®ˆ
            }
            
            search = GoogleSearch(params)
            response = search.get_dict()
            
            # è¨˜éŒ„åŸå§‹å›æ‡‰åˆ°æ—¥èªŒ
            logger.debug(f"[SerpAPI] åŸå§‹å›æ‡‰ keys: {response.keys()}")
            
            # è§£æçµæœ
            results = []
            
            # 1. è§£æ Knowledge Graph (çŸ¥è­˜åœ–è­œ)
            kg = response.get('knowledge_graph', {})
            if kg:
                title = kg.get('title', 'çŸ¥è­˜åœ–è­œ')
                desc = kg.get('description', '')
                
                # æå–é¡å¤–å±¬æ€§
                details = []
                for key in ['type', 'founded', 'headquarters', 'employees', 'ceo']:
                    val = kg.get(key)
                    if val:
                        details.append(f"{key}: {val}")
                        
                snippet = f"{desc}\n" + " | ".join(details) if details else desc
                
                results.append(SearchResult(
                    title=f"[çŸ¥è­˜åœ–è­œ] {title}",
                    snippet=snippet,
                    url=kg.get('source', {}).get('link', ''),
                    source="Google Knowledge Graph"
                ))
                
            # 2. è§£æ Answer Box (ç²¾é¸å›ç­”/è¡Œæƒ…å¡ç‰‡)
            ab = response.get('answer_box', {})
            if ab:
                ab_title = ab.get('title', 'ç²¾é¸å›ç­”')
                ab_snippet = ""
                
                # è²¡ç¶“é¡å›ç­”
                if ab.get('type') == 'finance_results':
                    stock = ab.get('stock', '')
                    price = ab.get('price', '')
                    currency = ab.get('currency', '')
                    movement = ab.get('price_movement', {})
                    mv_val = movement.get('percentage', 0)
                    mv_dir = movement.get('movement', '')
                    
                    ab_title = f"[è¡Œæƒ…å¡ç‰‡] {stock}"
                    ab_snippet = f"åƒ¹æ ¼: {price} {currency}\næ¼²è·Œ: {mv_dir} {mv_val}%"
                    
                    # æå–è¡¨æ ¼è³‡æ–™
                    if 'table' in ab:
                        table_data = []
                        for row in ab['table']:
                            if 'name' in row and 'value' in row:
                                table_data.append(f"{row['name']}: {row['value']}")
                        if table_data:
                            ab_snippet += "\n" + "; ".join(table_data)
                            
                # æ™®é€šæ–‡å­—å›ç­”
                elif 'snippet' in ab:
                    ab_snippet = ab.get('snippet', '')
                    list_items = ab.get('list', [])
                    if list_items:
                        ab_snippet += "\n" + "\n".join([f"- {item}" for item in list_items])
                
                elif 'answer' in ab:
                    ab_snippet = ab.get('answer', '')
                    
                if ab_snippet:
                    results.append(SearchResult(
                        title=f"[ç²¾é¸å›ç­”] {ab_title}",
                        snippet=ab_snippet,
                        url=ab.get('link', '') or ab.get('displayed_link', ''),
                        source="Google Answer Box"
                    ))

            # 3. è§£æ Related Questions (ç›¸é—œå•é¡Œ)
            rqs = response.get('related_questions', [])
            for rq in rqs[:3]: # å–å‰ 3 å€‹
                question = rq.get('question', '')
                snippet = rq.get('snippet', '')
                link = rq.get('link', '')
                
                if question and snippet:
                     results.append(SearchResult(
                        title=f"[ç›¸é—œå•é¡Œ] {question}",
                        snippet=snippet,
                        url=link,
                        source="Google Related Questions"
                     ))

            # 4. è§£æ Organic Results (è‡ªç„¶æœå°‹çµæœ)
            organic_results = response.get('organic_results', [])

            for item in organic_results[:max_results]:
                link = item.get('link', '')
                snippet = item.get('snippet', '')

                # å¢å¼·ï¼šå¦‚æœéœ€è¦ï¼Œè§£æç¶²é æ­£æ–‡
                # ç­–ç•¥ï¼šå¦‚æœæ‘˜è¦å¤ªçŸ­ï¼Œæˆ–è€…ç‚ºäº†ç²å–æ›´å¤šè³‡è¨Šï¼Œå¯ä»¥è«‹æ±‚ç¶²é 
                # é€™è£¡æˆ‘å€‘å°æ‰€æœ‰çµæœå˜—è©¦ç²å–æ­£æ–‡ï¼Œä½†ç‚ºäº†æ€§èƒ½ï¼Œåƒ…ç²å–å‰ 1000 å­—å…ƒ
                content = ""
                if link:
                   try:
                       fetched_content = fetch_url_content(link, timeout=5)
                       if fetched_content:
                           # å¦‚æœç²å–åˆ°äº†æ­£æ–‡ï¼Œå°‡å…¶æ‹¼æ¥åˆ° snippet ä¸­ï¼Œæˆ–è€…æ›¿æ› snippet
                           # é€™è£¡é¸æ“‡æ‹¼æ¥ï¼Œä¿ç•™åŸæ‘˜è¦
                           content = fetched_content
                           if len(content) > 500:
                               snippet = f"{snippet}\n\nã€ç¶²é è©³æƒ…ã€‘\n{content[:500]}..."
                           else:
                               snippet = f"{snippet}\n\nã€ç¶²é è©³æƒ…ã€‘\n{content}"
                   except Exception as e:
                       logger.debug(f"[SerpAPI] Fetch content failed: {e}")

                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=snippet[:1000], # é™åˆ¶ç¸½é•·åº¦
                    url=link,
                    source=item.get('source', self._extract_domain(link)),
                    published_date=item.get('date'),
                ))

            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except Exception as e:
            error_msg = str(e)
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """å¾ URL æå–åŸŸå"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            return parsed.netloc.replace('www.', '') or 'æœªçŸ¥ä¾†æº'
        except:
            return 'æœªçŸ¥ä¾†æº'


class BochaSearchProvider(BaseSearchProvider):
    """
    åšæŸ¥æœå°‹å¼•æ“
    
    ç‰¹é»ï¼š
    - å°ˆç‚º AI å„ªåŒ–çš„ä¸­æ–‡æœå°‹ API
    - çµæœæº–ç¢ºã€æ‘˜è¦å®Œæ•´
    - æ”¯æ´æ™‚é–“ç¯„åœéæ¿¾å’Œ AI æ‘˜è¦
    - ç›¸å®¹ Bing Search API æ ¼å¼
    
    æ–‡ä»¶ï¼šhttps://bocha-ai.feishu.cn/wiki/RXEOw02rFiwzGSkd9mUcqoeAnNK
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Bocha")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        """åŸ·è¡ŒåšæŸ¥æœå°‹"""
        try:
            import requests
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="requests æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install requests"
            )
        
        try:
            # API ç«¯é»
            url = "https://api.bocha.cn/v1/web-search"
            
            # è«‹æ±‚æ¨™é ­
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            # ç¢ºå®šæ™‚é–“ç¯„åœ
            freshness = "oneWeek"
            if days <= 1:
                freshness = "oneDay"
            elif days <= 7:
                freshness = "oneWeek"
            elif days <= 30:
                freshness = "oneMonth"
            else:
                freshness = "oneYear"

            # è«‹æ±‚åƒæ•¸ï¼ˆåš´æ ¼æŒ‰ç…§ API æ–‡ä»¶ï¼‰
            payload = {
                "query": query,
                "freshness": freshness,  # å‹•æ…‹æ™‚é–“ç¯„åœ
                "summary": True,  # å•Ÿç”¨ AI æ‘˜è¦
                "count": min(max_results, 50)  # æœ€å¤§ 50 æ¢
            }
            
            # åŸ·è¡Œæœå°‹
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            # æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼
            if response.status_code != 200:
                # å˜—è©¦è§£æéŒ¯èª¤è³‡è¨Š
                try:
                    if response.headers.get('content-type', '').startswith('application/json'):
                        error_data = response.json()
                        error_message = error_data.get('message', response.text)
                    else:
                        error_message = response.text
                except:
                    error_message = response.text
                
                # æ ¹æ“šéŒ¯èª¤ç¢¼è™•ç†
                if response.status_code == 403:
                    error_msg = f"é¤˜é¡ä¸è¶³: {error_message}"
                elif response.status_code == 401:
                    error_msg = f"API KEY ç„¡æ•ˆ: {error_message}"
                elif response.status_code == 400:
                    error_msg = f"è«‹æ±‚åƒæ•¸éŒ¯èª¤: {error_message}"
                elif response.status_code == 429:
                    error_msg = f"è«‹æ±‚é »ç‡é”åˆ°é™åˆ¶: {error_message}"
                else:
                    error_msg = f"HTTP {response.status_code}: {error_message}"
                
                logger.warning(f"[Bocha] æœå°‹å¤±æ•—: {error_msg}")
                
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # è§£æå›æ‡‰
            try:
                data = response.json()
            except ValueError as e:
                error_msg = f"å›æ‡‰ JSON è§£æå¤±æ•—: {str(e)}"
                logger.error(f"[Bocha] {error_msg}")
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # æª¢æŸ¥å›æ‡‰ä»£ç¢¼
            if data.get('code') != 200:
                error_msg = data.get('msg') or f"API è¿”å›éŒ¯èª¤ä»£ç¢¼: {data.get('code')}"
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # è¨˜éŒ„åŸå§‹å›æ‡‰åˆ°æ—¥èªŒ
            logger.info(f"[Bocha] æœå°‹å®Œæˆï¼Œquery='{query}'")
            logger.debug(f"[Bocha] åŸå§‹å›æ‡‰: {data}")
            
            # è§£ææœå°‹çµæœ
            results = []
            web_pages = data.get('data', {}).get('webPages', {})
            value_list = web_pages.get('value', [])
            
            for item in value_list[:max_results]:
                # å„ªå…ˆä½¿ç”¨ summaryï¼ˆAI æ‘˜è¦ï¼‰ï¼Œfallback åˆ° snippet
                snippet = item.get('summary') or item.get('snippet', '')
                
                # æˆªå–æ‘˜è¦é•·åº¦
                if snippet:
                    snippet = snippet[:500]
                
                results.append(SearchResult(
                    title=item.get('name', ''),
                    snippet=snippet,
                    url=item.get('url', ''),
                    source=item.get('siteName') or self._extract_domain(item.get('url', '')),
                    published_date=item.get('datePublished'),  # UTC+8 æ ¼å¼ï¼Œç„¡éœ€è½‰æ›
                ))
            
            logger.info(f"[Bocha] æˆåŠŸè§£æ {len(results)} æ¢çµæœ")
            
            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except requests.exceptions.Timeout:
            error_msg = "è«‹æ±‚è¶…æ™‚"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
        except requests.exceptions.RequestException as e:
            error_msg = f"ç¶²è·¯è«‹æ±‚å¤±æ•—: {str(e)}"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
        except Exception as e:
            error_msg = f"æœªçŸ¥éŒ¯èª¤: {str(e)}"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """å¾ URL æå–åŸŸåä½œç‚ºä¾†æº"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc.replace('www.', '')
            return domain or 'æœªçŸ¥ä¾†æº'
        except:
            return 'æœªçŸ¥ä¾†æº'


class SearchService:
    """
    æœå°‹æœå‹™
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å¤šå€‹æœå°‹å¼•æ“
    2. è‡ªå‹•æ•…éšœè½‰ç§»
    3. çµæœèšåˆå’Œæ ¼å¼åŒ–
    4. è³‡æ–™æºå¤±æ•—æ™‚çš„å¢å¼·æœå°‹ï¼ˆè‚¡åƒ¹ã€èµ°å‹¢ç­‰ï¼‰
    """
    
    # å¢å¼·æœå°‹é—œéµè©ç¯„æœ¬
    ENHANCED_SEARCH_KEYWORDS = [
        "{name} è‚¡ç¥¨ ä»Šæ—¥ è‚¡åƒ¹",
        "{name} {code} æœ€æ–° è¡Œæƒ… èµ°å‹¢",
        "{name} è‚¡ç¥¨ åˆ†æ èµ°å‹¢åœ–",
        "{name} Kç·š æŠ€è¡“åˆ†æ",
        "{name} {code} æ¼²è·Œ æˆäº¤é‡",
    ]
    
    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
    ):
        """
        åˆå§‹åŒ–æœå°‹æœå‹™
        
        Args:
            bocha_keys: åšæŸ¥æœå°‹ API Key åˆ—è¡¨
            tavily_keys: Tavily API Key åˆ—è¡¨
            serpapi_keys: SerpAPI Key åˆ—è¡¨
        """
        self._providers: List[BaseSearchProvider] = []
        
        # åˆå§‹åŒ–æœå°‹å¼•æ“ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
        # 1. Bocha å„ªå…ˆï¼ˆä¸­æ–‡æœå°‹å„ªåŒ–ï¼ŒAI æ‘˜è¦ï¼‰
        if bocha_keys:
            self._providers.append(BochaSearchProvider(bocha_keys))
            logger.info(f"å·²é…ç½® Bocha æœå°‹ï¼Œå…± {len(bocha_keys)} å€‹ API Key")
        
        # 2. Tavilyï¼ˆå…è²»é¡åº¦æ›´å¤šï¼Œæ¯æœˆ 1000 æ¬¡ï¼‰
        if tavily_keys:
            self._providers.append(TavilySearchProvider(tavily_keys))
            logger.info(f"å·²é…ç½® Tavily æœå°‹ï¼Œå…± {len(tavily_keys)} å€‹ API Key")
        
        # 3. SerpAPI ä½œç‚ºå‚™é¸ï¼ˆæ¯æœˆ 100 æ¬¡ï¼‰
        if serpapi_keys:
            self._providers.append(SerpAPISearchProvider(serpapi_keys))
            logger.info(f"å·²é…ç½® SerpAPI æœå°‹ï¼Œå…± {len(serpapi_keys)} å€‹ API Key")
        
        if not self._providers:
            logger.warning("æœªé…ç½®ä»»ä½•æœå°‹å¼•æ“ API Keyï¼Œæ–°èæœå°‹åŠŸèƒ½å°‡ä¸å¯ç”¨")
    
    @property
    def is_available(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æœå°‹å¼•æ“"""
        return any(p.is_available for p in self._providers)
    
    def search_stock_news(
        self,
        stock_code: str,
        stock_name: str,
        english_name: Optional[str] = None,
        max_results: int = 5,
        focus_keywords: Optional[List[str]] = None
    ) -> SearchResponse:
        """
        æœå°‹è‚¡ç¥¨ç›¸é—œæ–°è
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            max_results: æœ€å¤§è¿”å›çµæœæ•¸
            focus_keywords: é‡é»é—œæ³¨çš„é—œéµè©åˆ—è¡¨
            
        Returns:
            SearchResponse ç‰©ä»¶
        """
        # æ™ºæ…§ç¢ºå®šæœå°‹æ™‚é–“ç¯„åœ
        # ç­–ç•¥ï¼š
        # 1. é€±ä¸€è‡³é€±äº”ï¼šæœå°‹è¿‘ 3 å¤©ï¼ˆå°è‚¡æ–°èæ›´æ–°è¼ƒæ…¢ï¼Œä¸”éœ€è¦†è“‹æ˜¨æ—¥é—œéµè³‡è¨Šï¼‰
        # 2. é€±å…­ã€é€±æ—¥ï¼šæœå°‹è¿‘ 5 å¤©ï¼ˆè¦†è“‹æ•´é€±å‹•æ…‹ï¼‰
        today_weekday = datetime.now().weekday()
        if today_weekday >= 5: # é€±å…­(5)ã€é€±æ—¥(6)
            search_days = 5
        else: # é€±ä¸€(0) - é€±äº”(4)
            search_days = 3

        # æ§‹å»ºæœå°‹æŸ¥è©¢ï¼ˆå„ªåŒ–æœå°‹æ•ˆæœï¼‰
        if focus_keywords:
            # å¦‚æœæä¾›äº†é—œéµè©ï¼Œç›´æ¥ä½¿ç”¨é—œéµè©ä½œç‚ºæŸ¥è©¢
            query = " ".join(focus_keywords)
        else:
            # å°è‚¡å„ªåŒ–ï¼šå¦‚æœæ˜¯ 4 ä½æ•¸å­—ä»£ç¢¼ï¼ŒåŠ ä¸Š "å°è‚¡" é—œéµå­—ï¼Œä¸¦è™•ç†å¯èƒ½çš„è‹±æ–‡åç¨±
            is_tw_stock = len(stock_code) == 4 and stock_code.isdigit()
            
            # æª¢æŸ¥åç¨±æ˜¯å¦ç‚ºç´”è‹±æ–‡ (yfinance æŠ“å–çš„å¸¸è¦‹æƒ…æ³)
            import re
            is_english_name = bool(re.match(r'^[A-Za-z\s,\.]+$', stock_name))
            
            if is_tw_stock:
                # æ§‹å»ºæ ¸å¿ƒæœå°‹åç¨±ï¼šä¸­æ–‡ + è‹±æ–‡ï¼ˆå¦‚æœä¸åŒä¸”ä¸æ˜¯ç´”ä»£ç¢¼ï¼‰
                search_name = stock_name
                if english_name and english_name.lower() != stock_name.lower() and english_name != stock_code:
                    # é‡å°å°è‚¡ï¼Œè‹±æ–‡åé€šå¸¸å¤ªé•·ï¼Œå–å‰å…©å€‹å–®å­—æˆ–ç¸®å¯«
                    clean_eng = english_name.split(',')[0].split(' Corp')[0].split(' Inc')[0]
                    search_name = f"{stock_name} {clean_eng}"
                
                if is_english_name:
                    # å¦‚æœåªæœ‰è‹±æ–‡åï¼Œå„ªå…ˆä½¿ç”¨ä»£ç¢¼æœå°‹ï¼Œä¸¦åŠ ä¸Šå°è‚¡æ¨™ç±¤
                    query = f"å°è‚¡ {stock_code} æœ€æ–°æ¶ˆæ¯ æ–°è"
                else:
                    query = f"å°è‚¡ {search_name} {stock_code} æœ€æ–°æ¶ˆæ¯"
            else:
                query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"

        logger.info(f"æœå°‹è‚¡ç¥¨æ–°è: {stock_name}({stock_code}), query='{query}', æ™‚é–“ç¯„åœ: è¿‘ {search_days} å¤©")
        
        # ä¾æ¬¡å˜—è©¦å„å€‹æœå°‹å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results, days=search_days)
            
            if response.success and response.results:
                logger.info(f"ä½¿ç”¨ {provider.name} æœå°‹æˆåŠŸ")
                return response
            else:
                logger.warning(f"{provider.name} æœå°‹å¤±æ•—: {response.error_message}ï¼Œå˜—è©¦ä¸‹ä¸€å€‹å¼•æ“")
        
        # æ‰€æœ‰å¼•æ“éƒ½å¤±æ•—
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="æ‰€æœ‰æœå°‹å¼•æ“éƒ½ä¸å¯ç”¨æˆ–æœå°‹å¤±æ•—"
        )
    
    def search_stock_events(
        self,
        stock_code: str,
        stock_name: str,
        event_types: Optional[List[str]] = None
    ) -> SearchResponse:
        """
        æœå°‹è‚¡ç¥¨ç‰¹å®šäº‹ä»¶ï¼ˆå¹´å ±é å‘Šã€æ¸›æŒç­‰ï¼‰
        
        å°ˆé–€é‡å°äº¤æ˜“æ±ºç­–ç›¸é—œçš„é‡è¦äº‹ä»¶é€²è¡Œæœå°‹
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            event_types: äº‹ä»¶é¡å‹åˆ—è¡¨
            
        Returns:
            SearchResponse ç‰©ä»¶
        """
        if event_types is None:
            event_types = ["å¹´å ±é å‘Š", "æ¸›æŒå…¬å‘Š", "æ¥­ç¸¾å¿«å ±"]
        
        # æ§‹å»ºé‡å°æ€§æŸ¥è©¢
        event_query = " OR ".join(event_types)
        query = f"{stock_name} ({event_query})"
        
        logger.info(f"æœå°‹è‚¡ç¥¨äº‹ä»¶: {stock_name}({stock_code}) - {event_types}")
        
        # ä¾æ¬¡å˜—è©¦å„å€‹æœå°‹å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results=5)
            
            if response.success:
                return response
        
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="äº‹ä»¶æœå°‹å¤±æ•—"
        )
    
    def search_comprehensive_intel(
        self,
        stock_code: str,
        stock_name: str,
        english_name: Optional[str] = None,
        max_searches: int = 3
    ) -> Dict[str, SearchResponse]:
        """
        å¤šç¶­åº¦æƒ…å ±æœå°‹ï¼ˆåŒæ™‚ä½¿ç”¨å¤šå€‹å¼•æ“ã€å¤šå€‹ç¶­åº¦ï¼‰
        
        æœå°‹ç¶­åº¦ï¼š
        1. æœ€æ–°æ¶ˆæ¯ - è¿‘æœŸæ–°èå‹•æ…‹
        2. é¢¨éšªæ’æŸ¥ - æ¸›æŒã€è™•ç½°ã€åˆ©ç©º
        3. æ¥­ç¸¾é æœŸ - å¹´å ±é å‘Šã€æ¥­ç¸¾å¿«å ±
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            max_searches: æœ€å¤§æœå°‹æ¬¡æ•¸
            
        Returns:
            {ç¶­åº¦åç¨±: SearchResponse} å­—å…¸
        """
        results = {}
        search_count = 0
        
        is_tw_stock = len(stock_code) == 4 and stock_code.isdigit()
        prefix = "å°è‚¡ " if is_tw_stock else ""
        
        # æ§‹å»ºæ ¸å¿ƒæœå°‹åç¨±ï¼šä¸­æ–‡ + è‹±æ–‡ï¼ˆå¦‚æœä¸åŒä¸”ä¸æ˜¯ç´”ä»£ç¢¼ï¼‰
        search_name = stock_name
        if english_name and english_name.lower() != stock_name.lower() and english_name != stock_code:
            # é‡å°å°è‚¡ï¼Œè‹±æ–‡åé€šå¸¸å¤ªé•·ï¼Œå–å‰å…©å€‹å–®å­—æˆ–ç¸®å¯«
            if is_tw_stock:
                clean_eng = english_name.split(',')[0].split(' Corp')[0].split(' Inc')[0]
                search_name = f"{stock_name} {clean_eng}"
            else:
                search_name = f"{stock_name} {english_name}"
        
        # å®šç¾©æœå°‹ç¶­åº¦
        search_dimensions = [
            {
                'name': 'latest_news',
                'query': f"{prefix}{search_name} {stock_code} æœ€æ–° æ–°è é‡å¤§ äº‹ä»¶",
                'desc': 'æœ€æ–°æ¶ˆæ¯'
            },
            {
                'name': 'market_analysis',
                'query': f"{prefix}{search_name} {stock_code} ç ”å ± ç›®æ¨™åƒ¹ è©•ç´š æ·±åº¦åˆ†æ",
                'desc': 'æ©Ÿæ§‹åˆ†æ'
            },
            {
                'name': 'risk_check', 
                'query': f"{prefix}{search_name} {stock_code} æ¸›æŒ è™•ç½° é•è¦ è¨´è¨Ÿ åˆ©ç©º é¢¨éšª",
                'desc': 'é¢¨éšªæ’æŸ¥'
            },
            {
                'name': 'earnings',
                'query': f"{prefix}{search_name} {stock_code} æ¥­ç¸¾é å‘Š è²¡å ± ç‡Ÿæ”¶ æ·¨åˆ©æ½¤ åŒæ¯”å¢é•·",
                'desc': 'æ¥­ç¸¾é æœŸ'
            },
            {
                'name': 'industry',
                'query': f"{prefix}{search_name} {stock_code} æ‰€åœ¨è¡Œæ¥­ ç«¶çˆ­å°æ‰‹ å¸‚å ´ä»½é¡ è¡Œæ¥­å‰æ™¯",
                'desc': 'è¡Œæ¥­åˆ†æ'
            },
        ]
        
        logger.info(f"é–‹å§‹å¤šç¶­åº¦æƒ…å ±æœå°‹: {stock_name}({stock_code})")
        
        # è¼ªæµä½¿ç”¨ä¸åŒçš„æœå°‹å¼•æ“
        provider_index = 0
        
        for dim in search_dimensions:
            if search_count >= max_searches:
                break
            
            # é¸æ“‡æœå°‹å¼•æ“ï¼ˆè¼ªæµä½¿ç”¨ï¼‰
            available_providers = [p for p in self._providers if p.is_available]
            if not available_providers:
                break
            
            provider = available_providers[provider_index % len(available_providers)]
            provider_index += 1
            
            logger.info(f"[æƒ…å ±æœå°‹] {dim['desc']}: ä½¿ç”¨ {provider.name}")
            
            response = provider.search(dim['query'], max_results=3)
            results[dim['name']] = response
            search_count += 1
            
            if response.success:
                logger.info(f"[æƒ…å ±æœå°‹] {dim['desc']}: ç²å– {len(response.results)} æ¢çµæœ")
            else:
                logger.warning(f"[æƒ…å ±æœå°‹] {dim['desc']}: æœå°‹å¤±æ•— - {response.error_message}")
            
            # çŸ­æš«å»¶é²é¿å…è«‹æ±‚éå¿«
            time.sleep(0.5)
        
        return results
    
    def format_intel_report(self, intel_results: Dict[str, SearchResponse], stock_name: str) -> str:
        """
        æ ¼å¼åŒ–æƒ…å ±æœå°‹çµæœç‚ºå ±å‘Š
        
        Args:
            intel_results: å¤šç¶­åº¦æœå°‹çµæœ
            stock_name: è‚¡ç¥¨åç¨±
            
        Returns:
            æ ¼å¼åŒ–çš„æƒ…å ±å ±å‘Šæ–‡å­—
        """
        lines = [f"ã€{stock_name} æƒ…å ±æœå°‹çµæœã€‘"]
        
        # ç¶­åº¦å±•ç¤ºé †åº
        display_order = ['latest_news', 'market_analysis', 'risk_check', 'earnings', 'industry']
        
        for dim_name in display_order:
            if dim_name not in intel_results:
                continue
                
            resp = intel_results[dim_name]
            
            # ç²å–ç¶­åº¦æè¿°
            dim_desc = dim_name
            if dim_name == 'latest_news': dim_desc = 'ğŸ“° æœ€æ–°æ¶ˆæ¯'
            elif dim_name == 'market_analysis': dim_desc = 'ğŸ“ˆ æ©Ÿæ§‹åˆ†æ'
            elif dim_name == 'risk_check': dim_desc = 'âš ï¸ é¢¨éšªæ’æŸ¥'
            elif dim_name == 'earnings': dim_desc = 'ğŸ“Š æ¥­ç¸¾é æœŸ'
            elif dim_name == 'industry': dim_desc = 'ğŸ­ è¡Œæ¥­åˆ†æ'
            
            lines.append(f"\n{dim_desc} (ä¾†æº: {resp.provider}):")
            if resp.success and resp.results:
                # å¢åŠ é¡¯ç¤ºæ¢æ•¸
                for i, r in enumerate(resp.results[:4], 1):
                    date_str = f" [{r.published_date}]" if r.published_date else ""
                    lines.append(f"  {i}. {r.title}{date_str}")
                    # å¦‚æœæ‘˜è¦å¤ªçŸ­ï¼Œå¯èƒ½è³‡è¨Šé‡ä¸è¶³
                    snippet = r.snippet[:150] if len(r.snippet) > 20 else r.snippet
                    lines.append(f"     {snippet}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ç›¸é—œè³‡è¨Š")
        
        return "\n".join(lines)
    
    def batch_search(
        self,
        stocks: List[Dict[str, str]],
        max_results_per_stock: int = 3,
        delay_between: float = 1.0
    ) -> Dict[str, SearchResponse]:
        """
        æ‰¹é‡æœå°‹å¤šéš»è‚¡ç¥¨çš„æ–°èã€‚
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨
            max_results_per_stock: æ¯éš»è‚¡ç¥¨çš„æœ€å¤§çµæœæ•¸
            delay_between: æœå°‹é–“éš”ï¼ˆç§’ï¼‰
            
        Returns:
            çµæœå­—å…¸
        """
        results = {}
        
        for i, stock in enumerate(stocks):
            if i > 0:
                time.sleep(delay_between)
            
            code = stock.get('code', '')
            name = stock.get('name', '')
            
            response = self.search_stock_news(code, name, max_results_per_stock)
            results[code] = response
        
        return results

    def search_stock_price_fallback(
        self,
        stock_code: str,
        stock_name: str,
        max_attempts: int = 3,
        max_results: int = 5
    ) -> SearchResponse:
        """
        è³‡æ–™æºå¤±æ•—æ™‚çš„å¢å¼·æœå°‹ã€‚
        
        ç•¶æ‰€æœ‰è³‡æ–™æº (efinance, akshare, tushare, baostock, etc.) ç„¡æ³•ç²å–
        è‚¡ç¥¨è³‡æ–™æ™‚ï¼Œä½¿ç”¨æœå°‹å¼•æ“å°‹æ‰¾è‚¡ç¥¨è¶¨å‹¢å’Œåƒ¹æ ¼è³‡è¨Šï¼Œä½œç‚º AI åˆ†æçš„è£œå……è³‡æ–™ã€‚
        
        ç­–ç•¥ï¼š
        1. ä½¿ç”¨å¤šå€‹é—œéµè©ç¯„æœ¬æœå°‹
        2. ç‚ºæ¯å€‹é—œéµè©å˜—è©¦æ‰€æœ‰å¯ç”¨çš„æœå°‹å¼•æ“
        3. èšåˆä¸¦å»é‡çµæœ
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            max_attempts: æœ€å¤§æœå°‹å˜—è©¦æ¬¡æ•¸ï¼ˆä½¿ç”¨ä¸åŒé—œéµè©ï¼‰
            max_results: è¿”å›çš„æœ€å¤§çµæœæ•¸
            
        Returns:
            åŒ…å«èšåˆçµæœçš„ SearchResponse ç‰©ä»¶
        """

        if not self.is_available:
            return SearchResponse(
                query=f"{stock_name} è‚¡åƒ¹èµ°å‹¢",
                results=[],
                provider="None",
                success=False,
                error_message="æœªé…ç½®æœå°‹å¼•æ“ API Key"
            )
        
        logger.info(f"[å¢å¼·æœå°‹] è³‡æ–™æºå¤±æ•—ï¼Œå•Ÿå‹•å¢å¼·æœå°‹: {stock_name}({stock_code})")
        
        all_results = []
        seen_urls = set()
        successful_providers = []
        
        # ä½¿ç”¨å¤šå€‹é—œéµè©ç¯„æœ¬æœå°‹
        for i, keyword_template in enumerate(self.ENHANCED_SEARCH_KEYWORDS[:max_attempts]):
            query = keyword_template.format(name=stock_name, code=stock_code)
            
            logger.info(f"[å¢å¼·æœå°‹] ç¬¬ {i+1}/{max_attempts} æ¬¡æœå°‹: {query}")
            
            # ä¾æ¬¡å˜—è©¦å„å€‹æœå°‹å¼•æ“
            for provider in self._providers:
                if not provider.is_available:
                    continue
                
                try:
                    response = provider.search(query, max_results=3)
                    
                    if response.success and response.results:
                        # å»é‡ä¸¦æ·»åŠ çµæœ
                        for result in response.results:
                            if result.url not in seen_urls:
                                seen_urls.add(result.url)
                                all_results.append(result)
                                
                        if provider.name not in successful_providers:
                            successful_providers.append(provider.name)
                        
                        logger.info(f"[å¢å¼·æœå°‹] {provider.name} è¿”å› {len(response.results)} æ¢çµæœ")
                        break  # æˆåŠŸå¾Œè·³åˆ°ä¸‹ä¸€å€‹é—œéµè©
                    else:
                        logger.debug(f"[å¢å¼·æœå°‹] {provider.name} ç„¡çµæœæˆ–å¤±æ•—")
                        
                except Exception as e:
                    logger.warning(f"[å¢å¼·æœå°‹] {provider.name} æœå°‹ç•°å¸¸: {e}")
                    continue
            
            # çŸ­æš«å»¶é²é¿å…è«‹æ±‚éå¿«
            if i < max_attempts - 1:
                time.sleep(0.5)
        
        # å½™ç¸½çµæœ
        if all_results:
            # æˆªå–å‰ max_results æ¢
            final_results = all_results[:max_results]
            provider_str = ", ".join(successful_providers) if successful_providers else "None"
            
            logger.info(f"[å¢å¼·æœå°‹] å®Œæˆï¼Œå…±ç²å– {len(final_results)} æ¢çµæœï¼ˆä¾†æº: {provider_str}ï¼‰")
            
            return SearchResponse(
                query=f"{stock_name}({stock_code}) è‚¡åƒ¹èµ°å‹¢",
                results=final_results,
                provider=provider_str,
                success=True,
            )
        else:
            logger.warning(f"[å¢å¼·æœå°‹] æ‰€æœ‰æœå°‹å‡æœªè¿”å›çµæœ")
            return SearchResponse(
                query=f"{stock_name}({stock_code}) è‚¡åƒ¹èµ°å‹¢",
                results=[],
                provider="None",
                success=False,
                error_message="å¢å¼·æœå°‹æœªæ‰¾åˆ°ç›¸é—œè³‡è¨Š"
            )

    def search_stock_with_enhanced_fallback(
        self,
        stock_code: str,
        stock_name: str,
        include_news: bool = True,
        include_price: bool = False,
        max_results: int = 5
    ) -> Dict[str, SearchResponse]:
        """
        ç¶œåˆæœå°‹ä»‹é¢ï¼ˆæ”¯æ´æ–°èå’Œè‚¡åƒ¹è³‡è¨Šï¼‰
        
        ç•¶ include_price=True æ™‚ï¼ŒæœƒåŒæ™‚æœå°‹æ–°èå’Œè‚¡åƒ¹è³‡è¨Šã€‚
        ä¸»è¦ç”¨æ–¼è³‡æ–™æºå®Œå…¨å¤±æ•—æ™‚çš„å…œåº•æ–¹æ¡ˆã€‚
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            include_news: æ˜¯å¦æœå°‹æ–°è
            include_price: æ˜¯å¦æœå°‹è‚¡åƒ¹/èµ°å‹¢è³‡è¨Š
            max_results: æ¯é¡æœå°‹çš„æœ€å¤§çµæœæ•¸
            
        Returns:
            {'news': SearchResponse, 'price': SearchResponse} å­—å…¸
        """
        results = {}
        
        if include_news:
            results['news'] = self.search_stock_news(
                stock_code, 
                stock_name, 
                max_results=max_results
            )
        
        if include_price:
            results['price'] = self.search_stock_price_fallback(
                stock_code,
                stock_name,
                max_attempts=3,
                max_results=max_results
            )
        
        return results

    def format_price_search_context(self, response: SearchResponse) -> str:
        """
        å°‡è‚¡åƒ¹æœå°‹çµæœæ ¼å¼åŒ–ç‚º AI åˆ†æä¸Šä¸‹æ–‡
        
        Args:
            response: æœå°‹å›æ‡‰ç‰©ä»¶
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—ï¼Œå¯ç›´æ¥ç”¨æ–¼ AI åˆ†æ
        """
        if not response.success or not response.results:
            return "ã€è‚¡åƒ¹èµ°å‹¢æœå°‹ã€‘æœªæ‰¾åˆ°ç›¸é—œè³‡è¨Šï¼Œè«‹ä»¥å…¶ä»–ç®¡é“è³‡æ–™ç‚ºæº–ã€‚"
        
        lines = [
            f"ã€è‚¡åƒ¹èµ°å‹¢æœå°‹çµæœã€‘ï¼ˆä¾†æº: {response.provider}ï¼‰",
            "âš ï¸ æ³¨æ„ï¼šä»¥ä¸‹è³‡è¨Šä¾†è‡ªç¶²è·¯æœå°‹ï¼Œåƒ…ä¾›åƒè€ƒï¼Œå¯èƒ½å­˜åœ¨å»¶é²æˆ–ä¸æº–ç¢ºã€‚",
            ""
        ]
        
        for i, result in enumerate(response.results, 1):
            date_str = f" [{result.published_date}]" if result.published_date else ""
            lines.append(f"{i}. ã€{result.source}ã€‘{result.title}{date_str}")
            lines.append(f"   {result.snippet[:200]}...")
            lines.append("")
        
        return "\n".join(lines)


# === ä¾¿æ·å‡½æ•¸ ===
_search_service: Optional[SearchService] = None


def get_search_service() -> SearchService:
    """ç²å–æœå°‹æœå‹™å–®é«”"""
    global _search_service
    
    if _search_service is None:
        from tradingagents.daily_analysis.config import get_config
        config = get_config()
        
        _search_service = SearchService(
            bocha_keys=config.bocha_api_keys,
            tavily_api_keys=config.tavily_api_keys,
            serpapi_keys=config.serpapi_keys,
        )
    
    return _search_service


def reset_search_service() -> None:
    """é‡ç½®æœå°‹æœå‹™ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
    global _search_service
    _search_service = None


if __name__ == "__main__":
    # æ¸¬è©¦æœå°‹æœå‹™
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
    )
    
    # æ‰‹å‹•æ¸¬è©¦ï¼ˆéœ€è¦é…ç½® API Keyï¼‰
    service = get_search_service()
    
    if service.is_available:
        print("=== æ¸¬è©¦è‚¡ç¥¨æ–°èæœå°‹ ===")
        response = service.search_stock_news("300389", "è‰¾æ¯”æ£®")
        print(f"æœå°‹ç‹€æ…‹: {'æˆåŠŸ' if response.success else 'å¤±æ•—'}")
        print(f"æœå°‹å¼•æ“: {response.provider}")
        print(f"çµæœæ•¸é‡: {len(response.results)}")
        print(f"è€—æ™‚: {response.search_time:.2f}s")
        print("\n" + response.to_context())
    else:
        print("æœªé…ç½®æœå°‹å¼•æ“ API Keyï¼Œè·³éæ¸¬è©¦")
