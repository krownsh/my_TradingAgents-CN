# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ± - å­˜å„²å±¤
===================================

è·è²¬ï¼š
1. ç®¡ç† SQLite è³‡æ–™åº«é€£æ¥ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
2. å®šç¾© ORM æ•¸æ“šæ¨¡å‹
3. æä¾›æ•¸æ“šå­˜å–æ¥å£
4. å¯¦ç¾æ™ºèƒ½æ›´æ–°é‚è¼¯ï¼ˆæ–·é»çºŒå‚³ï¼‰
"""

import atexit
import hashlib
import json
import logging
import re
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict, Any, TYPE_CHECKING
from pathlib import Path

import pandas as pd
from sqlalchemy import (
    create_engine,
    Column,
    String,
    Float,
    Date,
    DateTime,
    Integer,
    Index,
    UniqueConstraint,
    Text,
    select,
    and_,
    desc,
)
from sqlalchemy.orm import (
    declarative_base,
    sessionmaker,
    Session,
)
from sqlalchemy.exc import IntegrityError

from tradingagents.daily_analysis.config import get_config

logger = logging.getLogger(__name__)

# SQLAlchemy ORM åŸºé¡
Base = declarative_base()

if TYPE_CHECKING:
    from tradingagents.daily_analysis.search_service import SearchResponse


# === æ•¸æ“šæ¨¡å‹å®šç¾© ===

class StockDaily(Base):
    """
    è‚¡ç¥¨æ—¥ç·šæ•¸æ“šæ¨¡å‹
    
    å­˜å„²æ¯æ—¥è¡Œæƒ…æ•¸æ“šå’Œè¨ˆç®—çš„æŠ€è¡“æŒ‡æ¨™
    æ”¯æŒå¤šè‚¡ç¥¨ã€å¤šæ—¥æœŸçš„å”¯ä¸€ç´„æŸ
    """
    __tablename__ = 'stock_daily'
    
    # ä¸»éµ
    id = Column(Integer, primary_key=True, autoincrement=True)
    
    # è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ 600519, 000001ï¼‰
    code = Column(String(10), nullable=False, index=True)
    
    # äº¤æ˜“æ—¥æœŸ
    date = Column(Date, nullable=False, index=True)
    
    # OHLC æ•¸æ“š
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    
    # æˆäº¤æ•¸æ“š
    volume = Column(Float)  # æˆäº¤é‡ï¼ˆè‚¡ï¼‰
    amount = Column(Float)  # æˆäº¤é¡ï¼ˆå…ƒï¼‰
    pct_chg = Column(Float)  # æ¼²è·Œå¹…ï¼ˆ%ï¼‰
    
    # æŠ€è¡“æŒ‡æ¨™
    ma5 = Column(Float)
    ma10 = Column(Float)
    ma20 = Column(Float)
    volume_ratio = Column(Float)  # é‡æ¯”
    
    # å°ç£è‚¡ç¥¨ç‰¹æœ‰ç±Œç¢¼æ•¸æ“š
    foreign_buy = Column(Float)    # å¤–è³‡è²·è³£è¶…
    it_buy = Column(Float)         # æŠ•ä¿¡è²·è³£è¶…
    dealers_buy = Column(Float)    # è‡ªç‡Ÿå•†è²·è³£è¶…
    margin_buy = Column(Float)     # èè³‡è²·è³£
    short_buy = Column(Float)      # èåˆ¸è²·è³£
    revenue_yoy = Column(Float)    # ç‡Ÿæ”¶å¹´å¢ç‡ (%)
    
    # æ•¸æ“šä¾†æº
    data_source = Column(String(50))  # è¨˜éŒ„æ•¸æ“šä¾†æºï¼ˆå¦‚ AkshareFetcherï¼‰
    
    # æ›´æ–°æ™‚é–“
    created_at = Column(DateTime, default=datetime.now)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)
    
    # å”¯ä¸€ç´„æŸï¼šåŒä¸€è‚¡ç¥¨åŒä¸€æ—¥æœŸåªèƒ½æœ‰ä¸€æ¢æ•¸æ“š
    __table_args__ = (
        UniqueConstraint('code', 'date', name='uix_code_date'),
        Index('ix_code_date', 'code', 'date'),
    )
    
    def __repr__(self):
        return f"<StockDaily(code={self.code}, date={self.date}, close={self.close})>"
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'code': self.code,
            'date': self.date,
            'open': self.open,
            'high': self.high,
            'low': self.low,
            'close': self.close,
            'volume': self.volume,
            'amount': self.amount,
            'pct_chg': self.pct_chg,
            'ma5': self.ma5,
            'ma10': self.ma10,
            'ma20': self.ma20,
            'volume_ratio': self.volume_ratio,
            'foreign_buy': self.foreign_buy,
            'it_buy': self.it_buy,
            'dealers_buy': self.dealers_buy,
            'margin_buy': self.margin_buy,
            'short_buy': self.short_buy,
            'revenue_yoy': self.revenue_yoy,
            'data_source': self.data_source,
        }


class NewsIntel(Base):
    """
    æ–°èæƒ…å ±æ•¸æ“šæ¨¡å‹

    å­˜å„²æœå°‹åˆ°çš„æ–°èæƒ…å ±æ¢ç›®ï¼Œç”¨æ–¼å¾ŒçºŒåˆ†æèˆ‡æŸ¥è©¢
    """
    __tablename__ = 'news_intel'

    id = Column(Integer, primary_key=True, autoincrement=True)

    # é—œè¯ç”¨æˆ¶æŸ¥è©¢æ“ä½œ
    query_id = Column(String(64), index=True)

    # è‚¡ç¥¨ä¿¡æ¯
    code = Column(String(10), nullable=False, index=True)
    name = Column(String(50))

    # æœå°‹ä¸Šä¸‹æ–‡
    dimension = Column(String(32), index=True)  # latest_news / risk_check / earnings / market_analysis / industry
    query = Column(String(255))
    provider = Column(String(32), index=True)

    # æ–°èå…§å®¹
    title = Column(String(300), nullable=False)
    snippet = Column(Text)
    url = Column(String(1000), nullable=False)
    source = Column(String(100))
    published_date = Column(DateTime, index=True)

    # å…¥åº«æ™‚é–“
    fetched_at = Column(DateTime, default=datetime.now, index=True)
    query_source = Column(String(32), index=True)  # bot/web/cli/system
    requester_platform = Column(String(20))
    requester_user_id = Column(String(64))
    requester_user_name = Column(String(64))
    requester_chat_id = Column(String(64))
    requester_message_id = Column(String(64))
    requester_query = Column(String(255))

    __table_args__ = (
        UniqueConstraint('url', name='uix_news_url'),
        Index('ix_news_code_pub', 'code', 'published_date'),
    )

    def __repr__(self) -> str:
        return f"<NewsIntel(code={self.code}, title={self.title[:20]}...)>"


class AnalysisHistory(Base):
    """
    åˆ†æçµæœæ­·å²è¨˜éŒ„æ¨¡å‹

    ä¿å­˜æ¯æ¬¡åˆ†æçµæœï¼Œæ”¯æŒæŒ‰ query_id/è‚¡ç¥¨ä»£ç¢¼æª¢ç´¢
    """
    __tablename__ = 'analysis_history'

    id = Column(Integer, primary_key=True, autoincrement=True)

    # é—œè¯æŸ¥è©¢éˆè·¯
    query_id = Column(String(64), index=True)

    # è‚¡ç¥¨ä¿¡æ¯
    code = Column(String(10), nullable=False, index=True)
    name = Column(String(50))
    report_type = Column(String(16), index=True)

    # æ ¸å¿ƒçµè«–
    sentiment_score = Column(Integer)
    operation_advice = Column(String(20))
    trend_prediction = Column(String(50))
    analysis_summary = Column(Text)

    # è©³ç´°æ•¸æ“š
    raw_result = Column(Text)
    news_content = Column(Text)
    context_snapshot = Column(Text)

    # ç‹™æ“Šé»ä½ï¼ˆç”¨æ–¼å›æ¸¬ï¼‰
    ideal_buy = Column(Float)
    secondary_buy = Column(Float)
    stop_loss = Column(Float)
    take_profit = Column(Float)

    created_at = Column(DateTime, default=datetime.now, index=True)

    __table_args__ = (
        Index('ix_analysis_code_time', 'code', 'created_at'),
    )

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'id': self.id,
            'query_id': self.query_id,
            'code': self.code,
            'name': self.name,
            'report_type': self.report_type,
            'sentiment_score': self.sentiment_score,
            'operation_advice': self.operation_advice,
            'trend_prediction': self.trend_prediction,
            'analysis_summary': self.analysis_summary,
            'raw_result': self.raw_result,
            'news_content': self.news_content,
            'context_snapshot': self.context_snapshot,
            'ideal_buy': self.ideal_buy,
            'secondary_buy': self.secondary_buy,
            'stop_loss': self.stop_loss,
            'take_profit': self.take_profit,
            'created_at': self.created_at.isoformat() if self.created_at else None,
        }


class DatabaseManager:
    """
    è³‡æ–™åº«ç®¡ç†å™¨ - å–®ä¾‹æ¨¡å¼
    
    è·è²¬ï¼š
    1. ç®¡ç†è³‡æ–™åº«é€£æ¥æ± 
    2. æä¾› Session ä¸Šä¸‹æ–‡ç®¡ç†
    3. å°è£æ•¸æ“šå­˜å–æ“ä½œ
    """
    
    _instance: Optional['DatabaseManager'] = None
    
    def __new__(cls, *args, **kwargs):
        """å–®ä¾‹æ¨¡å¼å¯¦ç¾"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self, db_url: Optional[str] = None):
        """
        åˆå§‹åŒ–è³‡æ–™åº«ç®¡ç†å™¨
        
        Args:
            db_url: è³‡æ–™åº«é€£æ¥ URLï¼ˆå¯é¸ï¼Œé»˜èªå¾é…ç½®è®€å–ï¼‰
        """
        if self._initialized:
            return
        
        if db_url is None:
            config = get_config()
            db_url = config.get_db_url()
        
        # å»ºç«‹è³‡æ–™åº«å¼•æ“
        self._engine = create_engine(
            db_url,
            echo=False,  # è¨­ç‚º True å¯æŸ¥çœ‹ SQL èªå¥
            pool_pre_ping=True,  # é€£æ¥å¥åº·æª¢æŸ¥
        )
        
        # å»ºç«‹ Session å·¥å» 
        self._SessionLocal = sessionmaker(
            bind=self._engine,
            autocommit=False,
            autoflush=False,
        )
        
        # å»ºç«‹æ‰€æœ‰è¡¨
        Base.metadata.create_all(self._engine)

        self._initialized = True
        logger.info(f"è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ: {db_url}")

        # è¨»å†Šé€€å‡ºé‰¤å­ï¼Œç¢ºä¿ç¨‹åºé€€å‡ºæ™‚é—œé–‰è³‡æ–™åº«é€£æ¥
        atexit.register(DatabaseManager._cleanup_engine, self._engine)
    
    @classmethod
    def get_instance(cls) -> 'DatabaseManager':
        """ç²å–å–®ä¾‹å¯¦ä¾‹"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    @classmethod
    def reset_instance(cls) -> None:
        """é‡ç½®å–®ä¾‹ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
        if cls._instance is not None:
            cls._instance._engine.dispose()
            cls._instance = None

    @classmethod
    def _cleanup_engine(cls, engine) -> None:
        """
        æ¸…ç†è³‡æ–™åº«å¼•æ“ï¼ˆatexit é‰¤å­ï¼‰

        ç¢ºä¿ç¨‹åºé€€å‡ºæ™‚é—œé–‰æ‰€æœ‰è³‡æ–™åº«é€£æ¥ï¼Œé¿å… ResourceWarning

        Args:
            engine: SQLAlchemy å¼•æ“å°è±¡
        """
        try:
            if engine is not None:
                engine.dispose()
                logger.debug("è³‡æ–™åº«å¼•æ“å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†è³‡æ–™åº«å¼•æ“æ™‚å‡ºéŒ¯: {e}")
    
    def get_session(self) -> Session:
        """
        ç²å–è³‡æ–™åº« Session
        
        ä½¿ç”¨ç¤ºä¾‹:
            with db.get_session() as session:
                # åŸ·è¡ŒæŸ¥è©¢
                session.commit()  # å¦‚æœéœ€è¦
        """
        session = self._SessionLocal()
        try:
            return session
        except Exception:
            session.close()
            raise
    
    def has_today_data(self, code: str, target_date: Optional[date] = None) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦å·²æœ‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        ç”¨æ–¼æ–·é»çºŒå‚³é‚è¼¯ï¼šå¦‚æœå·²æœ‰æ•¸æ“šå‰‡è·³éç¶²çµ¡è«‹æ±‚
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            target_date: ç›®æ¨™æ—¥æœŸï¼ˆé»˜èªä»Šå¤©ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨æ•¸æ“š
        """
        if target_date is None:
            target_date = date.today()
        
        with self.get_session() as session:
            result = session.execute(
                select(StockDaily).where(
                    and_(
                        StockDaily.code == code,
                        StockDaily.date == target_date
                    )
                )
            ).scalar_one_or_none()
            
            return result is not None
    
    def get_latest_data(
        self, 
        code: str, 
        days: int = 2
    ) -> List[StockDaily]:
        """
        ç²å–æœ€è¿‘ N å¤©çš„æ•°æ®
        
        ç”¨æ–¼è¨ˆç®—"ç›¸æ¯”æ˜¨æ—¥"çš„è®ŠåŒ–
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            days: ç²å–å¤©æ•¸
            
        Returns:
            StockDaily å°è±¡åˆ—è¡¨ï¼ˆæŒ‰æ—¥æœŸé™åºï¼‰
        """
        with self.get_session() as session:
            results = session.execute(
                select(StockDaily)
                .where(StockDaily.code == code)
                .order_by(desc(StockDaily.date))
                .limit(days)
            ).scalars().all()
            
            return list(results)

    def save_news_intel(
        self,
        code: str,
        name: str,
        dimension: str,
        query: str,
        response: 'SearchResponse',
        query_context: Optional[Dict[str, str]] = None
    ) -> int:
        """
        ä¿å­˜æ–°èæƒ…å ±åˆ°è³‡æ–™åº«

        å»é‡ç­–ç•¥ï¼š
        - å„ªå…ˆæŒ‰ URL å»é‡ï¼ˆå”¯ä¸€ç´„æŸï¼‰
        - URL ç¼ºå¤±æ™‚æŒ‰ title + source + published_date é€²è¡Œè»Ÿå»é‡

        é—œè¯ç­–ç•¥ï¼š
        - query_context è¨˜éŒ„ç”¨æˆ¶æŸ¥è©¢ä¿¡æ¯ï¼ˆå¹³å°ã€ç”¨æˆ¶ã€æœƒè©±ã€åŸå§‹æŒ‡ä»¤ç­‰ï¼‰
        """
        if not response or not response.results:
            return 0

        saved_count = 0

        with self.get_session() as session:
            try:
                for item in response.results:
                    title = (item.title or '').strip()
                    url = (item.url or '').strip()
                    source = (item.source or '').strip()
                    snippet = (item.snippet or '').strip()
                    published_date = self._parse_published_date(item.published_date)

                    if not title and not url:
                        continue

                    url_key = url or self._build_fallback_url_key(
                        code=code,
                        title=title,
                        source=source,
                        published_date=published_date
                    )

                    # å„ªå…ˆæŒ‰ URL æˆ–å…œåº•éµå»é‡
                    existing = session.execute(
                        select(NewsIntel).where(NewsIntel.url == url_key)
                    ).scalar_one_or_none()

                    if existing:
                        existing.name = name or existing.name
                        existing.dimension = dimension or existing.dimension
                        existing.query = query or existing.query
                        existing.provider = response.provider or existing.provider
                        existing.snippet = snippet or existing.snippet
                        existing.source = source or existing.source
                        existing.published_date = published_date or existing.published_date
                        existing.fetched_at = datetime.now()

                        if query_context:
                            existing.query_id = query_context.get("query_id") or existing.query_id
                            existing.query_source = query_context.get("query_source") or existing.query_source
                            existing.requester_platform = query_context.get("requester_platform") or existing.requester_platform
                            existing.requester_user_id = query_context.get("requester_user_id") or existing.requester_user_id
                            existing.requester_user_name = query_context.get("requester_user_name") or existing.requester_user_name
                            existing.requester_chat_id = query_context.get("requester_chat_id") or existing.requester_chat_id
                            existing.requester_message_id = query_context.get("requester_message_id") or existing.requester_message_id
                            existing.requester_query = query_context.get("requester_query") or existing.requester_query
                    else:
                        try:
                            with session.begin_nested():
                                record = NewsIntel(
                                    code=code,
                                    name=name,
                                    dimension=dimension,
                                    query=query,
                                    provider=response.provider,
                                    title=title,
                                    snippet=snippet,
                                    url=url_key,
                                    source=source,
                                    published_date=published_date,
                                    fetched_at=datetime.now(),
                                    query_id=(query_context or {}).get("query_id"),
                                    query_source=(query_context or {}).get("query_source"),
                                    requester_platform=(query_context or {}).get("requester_platform"),
                                    requester_user_id=(query_context or {}).get("requester_user_id"),
                                    requester_user_name=(query_context or {}).get("requester_user_name"),
                                    requester_chat_id=(query_context or {}).get("requester_chat_id"),
                                    requester_message_id=(query_context or {}).get("requester_message_id"),
                                    requester_query=(query_context or {}).get("requester_query"),
                                )
                                session.add(record)
                                session.flush()
                            saved_count += 1
                        except IntegrityError:
                            # å–®æ¢ URL å”¯ä¸€ç´„æŸè¡çªï¼ˆå¦‚ä½µç™¼æ’å…¥ï¼‰ï¼Œåƒ…è·³éæœ¬æ¢ï¼Œä¿ç•™æœ¬æ‰¹å…¶é¤˜æˆåŠŸé …
                            logger.debug("æ–°èæƒ…å ±é‡è¤‡ï¼ˆå·²è·³éï¼‰: %s %s", code, url_key)

                session.commit()
                logger.info(f"ä¿å­˜æ–°èæƒ…å ±æˆåŠŸ: {code}, æ–°å¢ {saved_count} æ¢")

            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜æ–°èæƒ…å ±å¤±æ•—: {e}")
                raise

        return saved_count

    def get_recent_news(self, code: str, days: int = 7, limit: int = 20) -> List[NewsIntel]:
        """
        ç²å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ N å¤©çš„æ–°èæƒ…å ±
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            results = session.execute(
                select(NewsIntel)
                .where(
                    and_(
                        NewsIntel.code == code,
                        NewsIntel.fetched_at >= cutoff_date
                    )
                )
                .order_by(desc(NewsIntel.fetched_at))
                .limit(limit)
            ).scalars().all()

            return list(results)

    def save_analysis_history(
        self,
        result: Any,
        query_id: str,
        report_type: str,
        news_content: Optional[str],
        context_snapshot: Optional[Dict[str, Any]] = None,
        save_snapshot: bool = True
    ) -> int:
        """
        ä¿å­˜åˆ†æçµæœæ­·å²è¨˜éŒ„
        """
        if result is None:
            return 0

        sniper_points = self._extract_sniper_points(result)
        raw_result = self._build_raw_result(result)
        context_text = None
        if save_snapshot and context_snapshot is not None:
            context_text = self._safe_json_dumps(context_snapshot)

        record = AnalysisHistory(
            query_id=query_id,
            code=result.code,
            name=result.name,
            report_type=report_type,
            sentiment_score=result.sentiment_score,
            operation_advice=result.operation_advice,
            trend_prediction=result.trend_prediction,
            analysis_summary=result.analysis_summary,
            raw_result=self._safe_json_dumps(raw_result),
            news_content=news_content,
            context_snapshot=context_text,
            ideal_buy=sniper_points.get("ideal_buy"),
            secondary_buy=sniper_points.get("secondary_buy"),
            stop_loss=sniper_points.get("stop_loss"),
            take_profit=sniper_points.get("take_profit"),
            created_at=datetime.now(),
        )

        with self.get_session() as session:
            try:
                session.add(record)
                session.commit()
                return 1
            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜åˆ†ææ­·å²å¤±æ•—: {e}")
                return 0

    def get_analysis_history(
        self,
        code: Optional[str] = None,
        query_id: Optional[str] = None,
        days: int = 30,
        limit: int = 50
    ) -> List[AnalysisHistory]:
        """
        æŸ¥è©¢åˆ†ææ­·å²è¨˜éŒ„
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            conditions = [AnalysisHistory.created_at >= cutoff_date]
            if code:
                conditions.append(AnalysisHistory.code == code)
            if query_id:
                conditions.append(AnalysisHistory.query_id == query_id)

            results = session.execute(
                select(AnalysisHistory)
                .where(and_(*conditions))
                .order_by(desc(AnalysisHistory.created_at))
                .limit(limit)
            ).scalars().all()

            return list(results)
    
    def get_data_range(
        self, 
        code: str, 
        start_date: date, 
        end_date: date
    ) -> List[StockDaily]:
        """
        ç²å–æŒ‡å®šæ—¥æœŸç¯„åœçš„æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            
        Returns:
            StockDaily å°è±¡åˆ—è¡¨
        """
        with self.get_session() as session:
            results = session.execute(
                select(StockDaily)
                .where(
                    and_(
                        StockDaily.code == code,
                        StockDaily.date >= start_date,
                        StockDaily.date <= end_date
                    )
                )
                .order_by(StockDaily.date)
            ).scalars().all()
            
            return list(results)
    
    def save_daily_data(
        self, 
        df: pd.DataFrame, 
        code: str,
        data_source: str = "Unknown"
    ) -> int:
        """
        ä¿å­˜æ—¥ç·šæ•¸æ“šåˆ°è³‡æ–™åº«
        
        ç­–ç•¥ï¼š
        - ä½¿ç”¨ UPSERT é‚è¼¯ï¼ˆå­˜åœ¨å‰‡æ›´æ–°ï¼Œä¸å­˜åœ¨å‰‡æ’å…¥ï¼‰
        - è·³éå·²å­˜åœ¨çš„æ•¸æ“šï¼Œé¿å…é‡è¤‡
        
        Args:
            df: åŒ…å«æ—¥ç·šæ•¸æ“šçš„ DataFrame
            code: è‚¡ç¥¨ä»£ç¢¼
            data_source: æ•¸æ“šä¾†æºåç¨±
            
        Returns:
            æ–°å¢/æ›´æ–°çš„è¨˜éŒ„æ•¸
        """
        if df is None or df.empty:
            logger.warning(f"ä¿å­˜æ•¸æ“šç‚ºç©ºï¼Œè·³é {code}")
            return 0
        
        saved_count = 0
        
        with self.get_session() as session:
            try:
                for _, row in df.iterrows():
                    # è§£ææ—¥æœŸ
                    row_date = row.get('date')
                    if isinstance(row_date, str):
                        row_date = datetime.strptime(row_date, '%Y-%m-%d').date()
                    elif isinstance(row_date, datetime):
                        row_date = row_date.date()
                    elif isinstance(row_date, pd.Timestamp):
                        row_date = row_date.date()
                    
                    # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = session.execute(
                        select(StockDaily).where(
                            and_(
                                StockDaily.code == code,
                                StockDaily.date == row_date
                            )
                        )
                    ).scalar_one_or_none()
                    
                    if existing:
                        # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                        existing.open = row.get('open')
                        existing.high = row.get('high')
                        existing.low = row.get('low')
                        existing.close = row.get('close')
                        existing.volume = row.get('volume')
                        existing.amount = row.get('amount')
                        existing.pct_chg = row.get('pct_chg')
                        existing.ma5 = row.get('ma5')
                        existing.ma10 = row.get('ma10')
                        existing.ma20 = row.get('ma20')
                        existing.volume_ratio = row.get('volume_ratio')
                        existing.foreign_buy = row.get('foreign_buy')
                        existing.it_buy = row.get('it_buy')
                        existing.dealers_buy = row.get('dealers_buy')
                        existing.margin_buy = row.get('margin_buy')
                        existing.short_buy = row.get('short_buy')
                        existing.revenue_yoy = row.get('revenue_yoy')
                        existing.data_source = data_source
                        existing.updated_at = datetime.now()
                    else:
                        # å»ºç«‹æ–°è¨˜éŒ„
                        record = StockDaily(
                            code=code,
                            date=row_date,
                            open=row.get('open'),
                            high=row.get('high'),
                            low=row.get('low'),
                            close=row.get('close'),
                            volume=row.get('volume'),
                            amount=row.get('amount'),
                            pct_chg=row.get('pct_chg'),
                            ma5=row.get('ma5'),
                            ma10=row.get('ma10'),
                            ma20=row.get('ma20'),
                            volume_ratio=row.get('volume_ratio'),
                            foreign_buy=row.get('foreign_buy'),
                            it_buy=row.get('it_buy'),
                            dealers_buy=row.get('dealers_buy'),
                            margin_buy=row.get('margin_buy'),
                            short_buy=row.get('short_buy'),
                            revenue_yoy=row.get('revenue_yoy'),
                            data_source=data_source,
                        )
                        session.add(record)
                        saved_count += 1
                
                session.commit()
                logger.info(f"ä¿å­˜ {code} æ•¸æ“šæˆåŠŸï¼Œæ–°å¢ {saved_count} æ¢")
                
            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜ {code} æ•¸æ“šå¤±æ•—: {e}")
                raise
        
        return saved_count
    
    def get_analysis_context(
        self, 
        code: str,
        target_date: Optional[date] = None
    ) -> Optional[Dict[str, Any]]:
        """
        ç²å–åˆ†ææ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•¸æ“š
        
        è¿”å›ä»Šæ—¥æ•¸æ“š + æ˜¨æ—¥æ•¸æ“šçš„å°æ¯”ä¿¡æ¯
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            target_date: ç›®æ¨™æ—¥æœŸï¼ˆé»˜èªä»Šå¤©ï¼‰
            
        Returns:
            åŒ…å«ä»Šæ—¥æ•¸æ“šã€æ˜¨æ—¥å°æ¯”ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        if target_date is None:
            target_date = date.today()
        
        # ç²å–æœ€è¿‘2å¤©æ•¸æ“š
        recent_data = self.get_latest_data(code, days=2)
        
        if not recent_data:
            logger.warning(f"æœªæ‰¾åˆ° {code} çš„æ•¸æ“š")
            return None
        
        today_data = recent_data[0]
        yesterday_data = recent_data[1] if len(recent_data) > 1 else None
        
        context = {
            'code': code,
            'date': today_data.date.isoformat(),
            'today': today_data.to_dict(),
        }
        
        if yesterday_data:
            context['yesterday'] = yesterday_data.to_dict()
            
            # è¨ˆç®—ç›¸æ¯”æ˜¨æ—¥çš„è®ŠåŒ–
            if yesterday_data.volume and yesterday_data.volume > 0:
                context['volume_change_ratio'] = round(
                    today_data.volume / yesterday_data.volume, 2
                )
            
            if yesterday_data.close and yesterday_data.close > 0:
                context['price_change_ratio'] = round(
                    (today_data.close - yesterday_data.close) / yesterday_data.close * 100, 2
                )
            
            # å‡ç·šå½¢æ…‹åˆ¤æ–·
            context['ma_status'] = self._analyze_ma_status(today_data)
        
        return context
    
    def _analyze_ma_status(self, data: StockDaily) -> str:
        """
        åˆ†æå‡ç·šå½¢æ…‹
        
        åˆ¤æ–·æ¢ä»¶ï¼š
        - å¤šé ­æ’åˆ—ï¼šclose > ma5 > ma10 > ma20
        - ç©ºé ­æ’åˆ—ï¼šclose < ma5 < ma10 < ma20
        - éœ‡ç›ªæ•´ç†ï¼šå…¶ä»–æƒ…æ³
        """
        close = data.close or 0
        ma5 = data.ma5 or 0
        ma10 = data.ma10 or 0
        ma20 = data.ma20 or 0
        
        if close > ma5 > ma10 > ma20 > 0:
            return "å¤šé ­æ’åˆ— ğŸ“ˆ"
        elif close < ma5 < ma10 < ma20 and ma20 > 0:
            return "ç©ºé ­æ’åˆ— ğŸ“‰"
        elif close > ma5 and ma5 > ma10:
            return "çŸ­æœŸå‘å¥½ ğŸ”¼"
        elif close < ma5 and ma5 < ma10:
            return "çŸ­æœŸèµ°å¼± ğŸ”½"
        else:
            return "éœ‡ç›ªæ•´ç† â†”ï¸"

    @staticmethod
    def _parse_published_date(value: Optional[str]) -> Optional[datetime]:
        """
        è§£æç™¼å¸ƒæ™‚é–“å­—ç¬¦ä¸²ï¼ˆå¤±æ•—è¿”å› Noneï¼‰
        """
        if not value:
            return None

        if isinstance(value, datetime):
            return value

        text = str(value).strip()
        if not text:
            return None

        # å„ªå…ˆå˜—è©¦ ISO æ ¼å¼
        try:
            return datetime.fromisoformat(text)
        except ValueError:
            pass

        for fmt in (
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y/%m/%d %H:%M:%S",
            "%Y/%m/%d %H:%M",
            "%Y/%m/%d",
        ):
            try:
                return datetime.strptime(text, fmt)
            except ValueError:
                continue

        return None

    @staticmethod
    def _safe_json_dumps(data: Any) -> str:
        """
        å®‰å…¨åºåˆ—åŒ–ç‚º JSON å­—ç¬¦ä¸²
        """
        try:
            return json.dumps(data, ensure_ascii=False, default=str)
        except Exception:
            return json.dumps(str(data), ensure_ascii=False)

    @staticmethod
    def _build_raw_result(result: Any) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´åˆ†æçµæœå­—å…¸
        """
        data = result.to_dict() if hasattr(result, "to_dict") else {}
        data.update({
            'data_sources': getattr(result, 'data_sources', ''),
            'raw_response': getattr(result, 'raw_response', None),
        })
        return data

    @staticmethod
    def _parse_sniper_value(value: Any) -> Optional[float]:
        """
        è§£æç‹™æ“Šé»ä½æ•¸å€¼
        """
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)

        text = str(value).replace(',', '').strip()
        if not text:
            return None

        match = re.search(r"-?\d+(?:\.\d+)?", text)
        if not match:
            return None
        try:
            return float(match.group())
        except ValueError:
            return None

    def _extract_sniper_points(self, result: Any) -> Dict[str, Optional[float]]:
        """
        æŠ½å–ç‹™æ“Šé»ä½æ•¸æ“š
        """
        raw_points = {}
        if hasattr(result, "get_sniper_points"):
            raw_points = result.get_sniper_points() or {}

        return {
            "ideal_buy": self._parse_sniper_value(raw_points.get("ideal_buy")),
            "secondary_buy": self._parse_sniper_value(raw_points.get("secondary_buy")),
            "stop_loss": self._parse_sniper_value(raw_points.get("stop_loss")),
            "take_profit": self._parse_sniper_value(raw_points.get("take_profit")),
        }

    @staticmethod
    def _build_fallback_url_key(
        code: str,
        title: str,
        source: str,
        published_date: Optional[datetime]
    ) -> str:
        """
        ç”Ÿæˆç„¡ URL æ™‚çš„å»é‡éµï¼ˆç¢ºä¿ç©©å®šä¸”è¼ƒçŸ­ï¼‰
        """
        date_str = published_date.isoformat() if published_date else ""
        raw_key = f"{code}|{title}|{source}|{date_str}"
        digest = hashlib.md5(raw_key.encode("utf-8")).hexdigest()
        return f"no-url:{code}:{digest}"


# ä¾¿æ·å‡½æ•¸
def get_db() -> DatabaseManager:
    """ç²å–è³‡æ–™åº«ç®¡ç†å™¨å¯¦ä¾‹çš„å¿«æ·æ–¹å¼"""
    return DatabaseManager.get_instance()


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    logging.basicConfig(level=logging.DEBUG)
    
    db = get_db()
    
    print("=== è³‡æ–™åº«æ¸¬è©¦ ===")
    print(f"è³‡æ–™åº«åˆå§‹åŒ–æˆåŠŸ")
    
    # æ¸¬è©¦æª¢æŸ¥ä»Šæ—¥æ•¸æ“š
    has_data = db.has_today_data('600519')
    print(f"èŒ…å°ä»Šæ—¥æ˜¯å¦æœ‰æ•¸æ“š: {has_data}")
    
    # æ¸¬è©¦ä¿å­˜æ•¸æ“š
    test_df = pd.DataFrame({
        'date': [date.today()],
        'open': [1800.0],
        'high': [1850.0],
        'low': [1780.0],
        'close': [1820.0],
        'volume': [10000000],
        'amount': [18200000000],
        'pct_chg': [1.5],
        'ma5': [1810.0],
        'ma10': [1800.0],
        'ma20': [1790.0],
        'volume_ratio': [1.2],
    })
    
    saved = db.save_daily_data(test_df, '600519', 'TestSource')
    print(f"ä¿å­˜æ¸¬è©¦æ•¸æ“š: {saved} æ¢")
    
    # æ¸¬è©¦ç²å–ä¸Šä¸‹æ–‡
    context = db.get_analysis_context('600519')
    print(f"åˆ†æä¸Šä¸‹æ–‡: {context}")
